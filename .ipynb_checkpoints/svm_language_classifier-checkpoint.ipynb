{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules, Methods, Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import re\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nikkud = ['ֹ', 'ְ', 'ּ', 'ׁ', 'ׂ', 'ָ', 'ֵ', 'ַ', 'ֶ', 'ִ', 'ֻ', 'ֱ', 'ֲ', 'ֳ', 'ׇ']\n",
    "alphabet = ['א','ב','ג','ד','ה','ו','ז','ח','ט','י','כ','ך','ל','מ','ם','נ','ן','ס','ע','פ','ף','צ','ץ','ק','ר','ש','ת']\n",
    "punctuation = ['״', '׳']\n",
    "characters = alphabet + nikkud + punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_to_vec(token, dim):\n",
    "    # print(token)\n",
    "    vec = [0]*dim\n",
    "    for i in range(len(token)):\n",
    "        vec[i * len(characters) + characters.index(token[i])] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(token):\n",
    "    return ''.join([c for c in token if c in characters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/vowelized_cal_texts/71667_each_training_data.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    data = [{'tag':d['tag'], 'word': clean(d['word'])} for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aramaic words in corpus: 71667\n",
      "Hebrew words in corpus: 71667\n"
     ]
    }
   ],
   "source": [
    "print('Aramaic words in corpus: ' + str(len([w for w in data if w['tag'] == 'A'])))\n",
    "print('Hebrew words in corpus: ' + str(len([w for w in data if w['tag'] == 'R'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:(len(data) * 3 // 4)]\n",
    "test_data = data[(len(data) * 3 //4):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 20000\n",
    "test_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968\n"
     ]
    }
   ],
   "source": [
    "train_labels = [d['tag'] for d in train_data]\n",
    "test_labels = [d['tag'] for d in test_data]\n",
    "\n",
    "dimension = max([len(d['word']) for d in data]) * len(characters)\n",
    "print(dimension)\n",
    "\n",
    "train_vecs = [tok_to_vec(d['word'], dimension) for d in train_data[:train_size]]\n",
    "test_vecs = [tok_to_vec(d['word'], dimension) for d in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = dimension // 1\n",
    "pca = PCA(pc).fit(train_vecs)\n",
    "train_pcs = pca.transform(train_vecs)\n",
    "test_pcs = pca.transform(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_clf = svm.SVC()#probability=True)\n",
    "lang_clf.fit(train_pcs, train_labels[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9368\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(np.array(lang_clf.predict(test_pcs[:test_size])) == np.array(test_labels[:test_size])) / test_size\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Talmud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nazir was not part of the training data\n",
    "with open('./data/aligned_talmud/Nazir.json', encoding='utf-8') as f:\n",
    "    naz = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['בָּעֵי',\n",
       " 'רַבִּי',\n",
       " 'יִרְמְיָה',\n",
       " 'רָקָב',\n",
       " 'הַבָּא',\n",
       " 'מִן',\n",
       " 'הֶעָקֵב',\n",
       " 'מַהוּ',\n",
       " 'כִּי',\n",
       " 'גָּמְרִינַן',\n",
       " 'רָקָב',\n",
       " 'הַבָּא',\n",
       " 'מִכּוּלֵּיהּ',\n",
       " 'מֵת',\n",
       " 'אֲבָל',\n",
       " 'דְּאָתֵי',\n",
       " 'מִן',\n",
       " 'עָקֵב',\n",
       " 'לָא',\n",
       " 'אוֹ',\n",
       " 'דִלְמָא',\n",
       " 'לָא',\n",
       " 'שְׁנָא']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = rd.randrange(len(naz))\n",
    "chunk = rd.randrange(len(naz[page]['content']))\n",
    "words = [word_forms[1] for word_forms in naz[page]['content'][chunk]['text']]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vecs = [tok_to_vec(word, dimension) for word in words]\n",
    "words_pcs = pca.transform(words_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naz_predictions = lang_clf.predict_proba(words_pcs)\n",
    "naz_predictions = lang_clf.predict(words_pcs)\n",
    "\n",
    "for i in range(len(words)):\n",
    "    print(words[i] + '\\t' + str(naz_predictions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968\n"
     ]
    }
   ],
   "source": [
    "test_labels = [d['tag'] for d in data]\n",
    "\n",
    "dimension = max([len(d['word']) for d in data]) * len(characters)\n",
    "print(dimension)\n",
    "\n",
    "test_vecs = [tok_to_vec(d['word'], dimension) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_clf = joblib.load('./src/languagetagger/GemaraLanguageTagger.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(np.array(lang_clf.predict(test_vecs[:500])) == np.array(test_labels[:500])) / 500\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Masekhet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nazir was not part of the training data\n",
    "with open('./data/aligned_talmud/Nazir.json', encoding='utf-8') as f:\n",
    "    naz = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['הָיוּ',\n",
       " 'לָהּ',\n",
       " 'מָעוֹת',\n",
       " 'סְתוּמִין',\n",
       " 'יִפְּלוּ',\n",
       " 'לִנְדָבָה',\n",
       " 'מָעוֹת',\n",
       " 'מְפוֹרָשִׁין',\n",
       " 'דְּמֵי',\n",
       " 'חַטָּאת',\n",
       " 'יֵלְכוּ',\n",
       " 'לְיָם',\n",
       " 'הַמֶּלַח',\n",
       " 'לֹא',\n",
       " 'נֶהֱנִין',\n",
       " 'וְלֹא',\n",
       " 'מוֹעֲלִין',\n",
       " 'בָּהֶן']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = rd.randrange(len(naz))\n",
    "chunk = rd.randrange(len(naz[page]['content']))\n",
    "words = [word_forms[1] for word_forms in naz[page]['content'][chunk]['text']]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vecs = [tok_to_vec(word, dimension) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHebrew      Aramaic\n",
      "הָיוּ\t[0.049861 0.950139]\n",
      "לָהּ\t[0.04982364 0.95017636]\n",
      "מָעוֹת\t[0.03085425 0.96914575]\n",
      "סְתוּמִין\t[0.05246527 0.94753473]\n",
      "יִפְּלוּ\t[0.02585053 0.97414947]\n",
      "לִנְדָבָה\t[0.04986535 0.95013465]\n",
      "מָעוֹת\t[0.03085425 0.96914575]\n",
      "מְפוֹרָשִׁין\t[0.09631687 0.90368313]\n",
      "דְּמֵי\t[0.93803868 0.06196132]\n",
      "חַטָּאת\t[0.04985473 0.95014527]\n",
      "יֵלְכוּ\t[0.11903322 0.88096678]\n",
      "לְיָם\t[0.04983734 0.95016266]\n",
      "הַמֶּלַח\t[0.01094101 0.98905899]\n",
      "לֹא\t[0.04985779 0.95014221]\n",
      "נֶהֱנִין\t[0.04981154 0.95018846]\n",
      "וְלֹא\t[0.04984848 0.95015152]\n",
      "מוֹעֲלִין\t[0.00383405 0.99616595]\n",
      "בָּהֶן\t[0.03025871 0.96974129]\n"
     ]
    }
   ],
   "source": [
    "naz_predictions = lang_clf.predict_proba(words_vecs)\n",
    "#naz_predictions = lang_clf.predict(words_vecs)\n",
    "\n",
    "print('\\t' + 'Hebrew      Aramaic')\n",
    "for i in range(len(words)):\n",
    "    print(words[i] + '\\t' + str(naz_predictions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/vowelized_cal_texts/stop_words.txt', encoding='utf-8') as f:\n",
    "    stops = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = [tuple(w.split('\\t')) for w in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('רַבִּי', '1222'),\n",
       " ('עַל', '1119'),\n",
       " ('אֶלָּא', '1110'),\n",
       " ('אֶת', '1051'),\n",
       " ('אוֹמֵר', '923'),\n",
       " ('הוּא', '875'),\n",
       " ('לֹא', '803'),\n",
       " ('הָא', '802'),\n",
       " ('אוֹ', '627'),\n",
       " ('כִּי', '613'),\n",
       " ('לוֹ', '593'),\n",
       " ('שֶׁל', '558'),\n",
       " ('בַּר', '546'),\n",
       " ('אִי', '541'),\n",
       " ('עַד', '509'),\n",
       " ('וְלֹא', '461'),\n",
       " ('מִן', '452'),\n",
       " ('אֵין', '446'),\n",
       " ('אִם', '443'),\n",
       " ('לִי', '437'),\n",
       " ('מִשּׁוּם', '426'),\n",
       " ('זֶה', '426'),\n",
       " ('הִיא', '408'),\n",
       " ('אָמַר', '397'),\n",
       " ('לָאו', '365'),\n",
       " ('אֶחָד', '351'),\n",
       " ('אוֹמְרִים', '337'),\n",
       " ('כָּל', '325'),\n",
       " ('בֵּין', '317'),\n",
       " ('מִי', '316'),\n",
       " ('אַף', '288'),\n",
       " ('וְאִם', '281'),\n",
       " ('יְהוּדָה', '279'),\n",
       " ('טָמֵא', '257'),\n",
       " ('אֵינוֹ', '246'),\n",
       " ('שֶׁהוּא', '239'),\n",
       " ('הָיָה', '235'),\n",
       " ('כֵּיוָן', '229'),\n",
       " ('לָךְ', '222'),\n",
       " ('מִפְּנֵי', '219'),\n",
       " ('אֲבָל', '219'),\n",
       " ('בֶּן', '218'),\n",
       " ('שִׁמְעוֹן', '215'),\n",
       " ('בֵּית', '201'),\n",
       " ('טָהוֹר', '199'),\n",
       " ('אַחַת', '197'),\n",
       " ('וְאִי', '186'),\n",
       " ('בּוֹ', '181'),\n",
       " ('בָּהּ', '180'),\n",
       " ('לָהּ', '169'),\n",
       " ('הָיוּ', '169'),\n",
       " ('עָלָיו', '164'),\n",
       " ('שֶׁאֵין', '162'),\n",
       " ('שְׁמַע', '146'),\n",
       " ('אָמְרוּ', '146'),\n",
       " ('יוֹם', '142'),\n",
       " ('וְעַל', '141'),\n",
       " ('כֹּל', '137'),\n",
       " ('שַׁמַּאי', '133'),\n",
       " ('הִלֵּל', '133'),\n",
       " ('וְכִי', '132'),\n",
       " ('וְכֵן', '129'),\n",
       " ('אָסוּר', '125'),\n",
       " ('לָהֶם', '121'),\n",
       " ('עֲקִיבָא', '120'),\n",
       " ('וּבֵית', '118'),\n",
       " ('יִשְׂרָאֵל', '116'),\n",
       " ('שֶׁנֶּאֱמַר', '116'),\n",
       " ('שְׁנֵי', '115'),\n",
       " ('שְׁתֵּי', '114'),\n",
       " ('מְטַמֵּא', '109'),\n",
       " ('גַּמְלִיאֵל', '107'),\n",
       " ('גַּבֵּי', '106'),\n",
       " ('מַהוּ', '103'),\n",
       " ('מַה', '103'),\n",
       " ('גַּב', '98'),\n",
       " ('כַּמָּה', '98'),\n",
       " ('וְרַב', '97'),\n",
       " ('וְהוּא', '95'),\n",
       " ('הֵן', '89'),\n",
       " ('אַרְבַּע', '88'),\n",
       " ('רַבָּן', '88'),\n",
       " ('לְמָה', '86'),\n",
       " ('שֶׁהִיא', '86'),\n",
       " ('עָלֶיהָ', '83'),\n",
       " ('עִם', '81'),\n",
       " ('נוֹתֵן', '79'),\n",
       " ('בְּנֵי', '78'),\n",
       " ('מְשַׁלֵּם', '72'),\n",
       " ('וְרַבִּי', '71'),\n",
       " ('אֵינָהּ', '70'),\n",
       " ('יֵשׁ', '69'),\n",
       " ('וַהֲדַר', '68'),\n",
       " ('מִמֶּנּוּ', '67'),\n",
       " ('אַרְבָּעָה', '66'),\n",
       " ('שֵׁנִי', '66'),\n",
       " ('דָּבָר', '65'),\n",
       " ('וְאָמַר', '65'),\n",
       " ('כְּגוֹן', '64'),\n",
       " ('דִּכְתִיב', '63'),\n",
       " ('אֲנִי', '63'),\n",
       " ('סָפֵק', '63'),\n",
       " ('אַחֵר', '62'),\n",
       " ('טוֹב', '61'),\n",
       " ('בַּת', '60'),\n",
       " ('בִּזְמַן', '60'),\n",
       " ('מִכָּאן', '59'),\n",
       " ('הֲדַר', '58'),\n",
       " ('מְאָה', '57'),\n",
       " ('עֲשָׂרָה', '57'),\n",
       " ('לְךָ', '57'),\n",
       " ('כָּאן', '56'),\n",
       " ('בַּעַל', '55'),\n",
       " ('לָהֶן', '55'),\n",
       " ('אֶפְשָׁר', '49'),\n",
       " ('צָרִיךְ', '49'),\n",
       " ('לְבֵית', '48'),\n",
       " ('כֵּן', '47'),\n",
       " ('הָרִאשׁוֹן', '46'),\n",
       " ('יָכוֹל', '46'),\n",
       " ('עֲלֵיהֶן', '45'),\n",
       " ('סוֹף', '43'),\n",
       " ('וְזֶה', '43'),\n",
       " ('אוֹתָהּ', '43'),\n",
       " ('בִּרְשׁוּת', '43'),\n",
       " ('וַדַּאי', '42'),\n",
       " ('וְעַד', '42'),\n",
       " ('מָה', '42'),\n",
       " ('קָדָשִׁים', '42'),\n",
       " ('שִׁבְעָה', '41'),\n",
       " ('רַבָּה', '40'),\n",
       " ('עֶשְׂרִים', '40'),\n",
       " ('שַׁבָּת', '39'),\n",
       " ('וּבֵין', '39'),\n",
       " ('מִמֶּנָּה', '39'),\n",
       " ('מְטַמְּאִין', '38'),\n",
       " ('בְּשַׁבָּת', '38'),\n",
       " ('יָדַע', '37'),\n",
       " ('מִדְרָס', '37'),\n",
       " ('יוֹחָנָן', '37'),\n",
       " ('אָכַל', '36'),\n",
       " ('יְדֵי', '36'),\n",
       " ('אַחַד', '36'),\n",
       " ('מְנָת', '36'),\n",
       " ('מוֹדֶה', '35'),\n",
       " ('אַתְּ', '35'),\n",
       " ('כְּלוּם', '35'),\n",
       " ('אוֹתָן', '35'),\n",
       " ('שְׁבִיעִית', '35'),\n",
       " ('וְעוֹד', '34'),\n",
       " ('וְאַף', '34'),\n",
       " ('מֵאָה', '34'),\n",
       " ('וּמִי', '33'),\n",
       " ('שָׁלֹשׁ', '33'),\n",
       " ('נִכְסֵי', '32'),\n",
       " ('רֹאשׁ', '32'),\n",
       " ('עֶשְׂרֵה', '32'),\n",
       " ('בְּיוֹם', '31'),\n",
       " ('חָמֵשׁ', '31'),\n",
       " ('אַרְבָּעִים', '30'),\n",
       " ('קָטָן', '30'),\n",
       " ('מְקַבֵּל', '30'),\n",
       " ('לְגַבֵּי', '29'),\n",
       " ('אַבָּא', '29'),\n",
       " ('חֲמִשָּׁה', '29'),\n",
       " ('זָרָה', '29'),\n",
       " ('עָלַי', '28'),\n",
       " ('מְבָרֵךְ', '28'),\n",
       " ('יָרָק', '28'),\n",
       " ('לְמָחָר', '28'),\n",
       " ('וְהִיא', '28'),\n",
       " ('כְּלָל', '27'),\n",
       " ('אָזְלָא', '27'),\n",
       " ('מַתִּיר', '27'),\n",
       " ('אוֹסֵר', '27'),\n",
       " ('מִכְּדֵי', '26'),\n",
       " ('מִצְטָרְפִין', '26'),\n",
       " ('נָכְרִי', '26'),\n",
       " ('לְפָנָיו', '25'),\n",
       " ('מְעָרְבִין', '25'),\n",
       " ('רְשׁוּת', '25'),\n",
       " ('בָּרוּךְ', '24'),\n",
       " ('וַחֲמִשָּׁה', '24'),\n",
       " ('אֲבָנִים', '24'),\n",
       " ('לְיִשְׂרָאֵל', '23'),\n",
       " ('וְכֵיוָן', '23'),\n",
       " ('שָׁנִים', '23'),\n",
       " ('כְּלִי', '22'),\n",
       " ('נָגַע', '22'),\n",
       " ('כֹּהֲנִים', '21'),\n",
       " ('לִידֵי', '21'),\n",
       " ('דֶּרֶךְ', '21'),\n",
       " ('בִּשְׁנֵי', '20'),\n",
       " ('וְכַמָּה', '20'),\n",
       " ('נֶאֱמַר', '20'),\n",
       " ('מְלֵאָה', '20'),\n",
       " ('עֲבוֹדָה', '20'),\n",
       " ('וּמִשּׁוּם', '19'),\n",
       " ('עֶשֶׂר', '19'),\n",
       " ('לִבְנֵי', '19'),\n",
       " ('יְהֵא', '19'),\n",
       " ('זֶרַע', '19'),\n",
       " ('קָנָה', '19'),\n",
       " ('מֵי', '19'),\n",
       " ('מֵתָה', '19'),\n",
       " ('הוֹאִיל', '18'),\n",
       " ('מְקַדֵּשׁ', '18'),\n",
       " ('תְּלָתִין', '18'),\n",
       " ('גְּבַר', '18'),\n",
       " ('אָמְרָה', '17'),\n",
       " ('מִין', '17'),\n",
       " ('פּוֹטֵר', '17'),\n",
       " ('שֶׁאֵינָהּ', '17'),\n",
       " ('דְּמֵי', '17'),\n",
       " ('מֵחֲמַת', '16'),\n",
       " ('צִבּוּר', '16'),\n",
       " ('אֶל', '16'),\n",
       " ('וְכֹל', '16'),\n",
       " ('הֵבִיא', '16'),\n",
       " ('דַּל', '16'),\n",
       " ('אַחֶרֶת', '16'),\n",
       " ('בְּיַד', '16'),\n",
       " ('רוּחַ', '16'),\n",
       " ('וְאַתְּ', '15'),\n",
       " ('עֶשְׂרִין', '15'),\n",
       " ('דָּם', '15'),\n",
       " ('זְכָרִים', '15'),\n",
       " ('וַהֲלֹא', '15'),\n",
       " ('מַכְשִׁיר', '15'),\n",
       " ('יֹאכַל', '15'),\n",
       " ('שׁוֹחֲטִין', '15'),\n",
       " ('כָרֵת', '15'),\n",
       " ('וְאָמְרוּ', '15'),\n",
       " ('שֶׁבַע', '14'),\n",
       " ('עוֹד', '14'),\n",
       " ('וְאַרְבַּע', '14'),\n",
       " ('עוֹבֵר', '14'),\n",
       " ('פְּסוּלִין', '14'),\n",
       " ('מֵאַחַר', '13'),\n",
       " ('פְּתַח', '13'),\n",
       " ('קוּם', '13'),\n",
       " ('קֶרֶן', '13'),\n",
       " ('וְאָסוּר', '13'),\n",
       " ('פָּרָה', '13'),\n",
       " ('צְרִיכָה', '13'),\n",
       " ('כִי', '13'),\n",
       " ('מוֹסִיף', '13'),\n",
       " ('וּבְנֵי', '13'),\n",
       " ('בִּירוּשָׁלַיִם', '13'),\n",
       " ('בְּחֶזְקַת', '13'),\n",
       " ('יָלֵיף', '12'),\n",
       " ('אָמַרְתָּ', '12'),\n",
       " ('דְּבַר', '12'),\n",
       " ('כְּבֵית', '12'),\n",
       " ('מֵעֶרֶב', '12'),\n",
       " ('בְּסוֹף', '12'),\n",
       " ('תֵּשַׁע', '12'),\n",
       " ('מְבַטֵּל', '12'),\n",
       " ('בְּנִכְסֵי', '12'),\n",
       " ('גָּמַר', '12'),\n",
       " ('חַי', '12'),\n",
       " ('תִּשְׁעָה', '12'),\n",
       " ('סְתָם', '12'),\n",
       " ('בַּיִת', '12'),\n",
       " ('בִּי', '11'),\n",
       " ('כְּלַפֵּי', '11'),\n",
       " ('מֵאַרְבַּע', '11'),\n",
       " ('הַזָּב', '11'),\n",
       " ('כְלוּם', '11'),\n",
       " ('מַצִּיל', '11'),\n",
       " ('מֵזִיד', '11'),\n",
       " ('מְטַמְּאָה', '11'),\n",
       " ('שְׁמָהּ', '11'),\n",
       " ('גְּמַר', '11'),\n",
       " ('מוֹסִיפִין', '11'),\n",
       " ('וּמוֹדֶה', '11'),\n",
       " ('שְׁאָר', '11'),\n",
       " ('אִלּוּ', '10'),\n",
       " ('שִׁעוּר', '10'),\n",
       " ('בְּתֵירָא', '10'),\n",
       " ('וּמָה', '10'),\n",
       " ('מְקַבְּלִין', '10'),\n",
       " ('בְּאֶרֶץ', '10'),\n",
       " ('וּבַת', '10'),\n",
       " ('חוֹטֵא', '10'),\n",
       " ('מֵעֲשָׂרָה', '10'),\n",
       " ('מְעָרֵב', '10'),\n",
       " ('מִצְטָרֵף', '10'),\n",
       " ('פֶּסַח', '10'),\n",
       " ('לָמָּה', '10'),\n",
       " ('בְּלֹא', '10'),\n",
       " ('לְקַבֵּל', '10'),\n",
       " ('בָּתֵּי', '9'),\n",
       " ('בְּאַרְבַּע', '9'),\n",
       " ('לְאַלְתַּר', '9'),\n",
       " ('נִיסָן', '9'),\n",
       " ('מְבָרְכִין', '9'),\n",
       " ('נָפְלָה', '9'),\n",
       " ('וְאַרְבָּעָה', '9'),\n",
       " ('בָּךְ', '9'),\n",
       " ('קִבֵּל', '9'),\n",
       " ('כְּבָר', '9'),\n",
       " ('לְתוֹכָן', '9'),\n",
       " ('גָּזַר', '9'),\n",
       " ('אֵם', '9'),\n",
       " ('לְרַבִּי', '9'),\n",
       " ('קָשֶׁה', '9'),\n",
       " ('מְמַעֵט', '9'),\n",
       " ('כָּתַב', '9'),\n",
       " ('מְעַכֵּב', '9'),\n",
       " ('שְׁטָרֵי', '9'),\n",
       " ('יְדִיעָה', '9'),\n",
       " ('שְׁמוּאֵל', '8'),\n",
       " ('תַּלְמִידֵי', '8'),\n",
       " ('מֵעֵין', '8'),\n",
       " ('לְשַׁבָּת', '8'),\n",
       " ('עָבַר', '8'),\n",
       " ('יְרוּשָׁלַיִם', '8'),\n",
       " ('לְשׁוּם', '8'),\n",
       " ('לְעִנְיַן', '8'),\n",
       " ('שֵׁמוֹת', '8'),\n",
       " ('תְּהֵא', '8'),\n",
       " ('יוֹסֵף', '8'),\n",
       " ('מְטַלְטְלִין', '8'),\n",
       " ('רוּם', '8'),\n",
       " ('בְּמָנֶה', '8'),\n",
       " ('אָכְלָה', '7'),\n",
       " ('שִׁבְעִים', '7'),\n",
       " ('אִילָנֵי', '7'),\n",
       " ('מַחֲזִיק', '7'),\n",
       " ('שָׁמַע', '7'),\n",
       " ('רָאִיתִי', '7'),\n",
       " ('בָּבָא', '7'),\n",
       " ('כָּתוּב', '7'),\n",
       " ('פָּרַח', '7'),\n",
       " ('קְנֵי', '7'),\n",
       " ('מִלֵּוִי', '7'),\n",
       " ('דְּמַאי', '7'),\n",
       " ('עָלֶיךָ', '7'),\n",
       " ('פִּסְקֵי', '7'),\n",
       " ('וְתִשְׁעָה', '7'),\n",
       " ('עָתִיד', '7'),\n",
       " ('בְּאַרְבָּעָה', '7'),\n",
       " ('וּבִזְמַן', '7'),\n",
       " ('אַבְנֵי', '7'),\n",
       " ('עֲנִיִּים', '7'),\n",
       " ('סְאִין', '7'),\n",
       " ('בְּסֶלַע', '7'),\n",
       " ('מְהַלֵּךְ', '7'),\n",
       " ('קָדְמָה', '6'),\n",
       " ('וּפָתַח', '6'),\n",
       " ('מִקְרָא', '6'),\n",
       " ('פָּטַר', '6'),\n",
       " ('מִבְּעוֹד', '6'),\n",
       " ('עַבְדֵי', '6'),\n",
       " ('תּוֹךְ', '6'),\n",
       " ('לְאַבָּא', '6'),\n",
       " ('גַּמְלָא', '6'),\n",
       " ('וְצָרִיךְ', '6'),\n",
       " ('וְנָפְלָה', '6'),\n",
       " ('מֶלֶךְ', '6'),\n",
       " ('שֶׁעֲשָׂאוֹ', '6'),\n",
       " ('עִקָּר', '6'),\n",
       " ('וְכָתוּב', '6'),\n",
       " ('וְשִׁבְעָה', '6'),\n",
       " ('בָּלַע', '6'),\n",
       " ('בְּחַיֵּי', '6'),\n",
       " ('וּשְׁמַע', '6'),\n",
       " ('מַעֲלֶה', '6'),\n",
       " ('מִיּוֹם', '6'),\n",
       " ('וְרַבָּן', '6'),\n",
       " ('דַּק', '6'),\n",
       " ('אֲכִילַת', '6'),\n",
       " ('דָּמָהּ', '6'),\n",
       " ('אֹתוֹ', '6'),\n",
       " ('אִשְׁתִּי', '6'),\n",
       " ('חָטָא', '6'),\n",
       " ('שָׁלַח', '6'),\n",
       " ('לְבַיִת', '6'),\n",
       " ('קוֹל', '6'),\n",
       " ('סְפִינָה', '6'),\n",
       " ('עָרֵי', '6'),\n",
       " ('וַאֲחֵרִים', '6'),\n",
       " ('הֲלָכָה', '6'),\n",
       " ('עַיִן', '6'),\n",
       " ('לִסְמוֹךְ', '5'),\n",
       " ('וּמֵתוּ', '5'),\n",
       " ('קְרִי', '5'),\n",
       " ('בִּרְכַּת', '5'),\n",
       " ('חֲבֶרְתָּהּ', '5'),\n",
       " ('הֱוֵי', '5'),\n",
       " ('וּבוֹ', '5'),\n",
       " ('לְסוֹף', '5'),\n",
       " ('עֲפַר', '5'),\n",
       " ('כְּאֶחָד', '5'),\n",
       " ('מְחַשֵּׁב', '5'),\n",
       " ('בְּנִיסָן', '5'),\n",
       " ('וְזָרַק', '5'),\n",
       " ('תְּהִי', '5'),\n",
       " ('טָבַע', '5'),\n",
       " ('אֲבִי', '5'),\n",
       " ('שְׁטָר', '5'),\n",
       " ('מַתְחִיל', '5'),\n",
       " ('דִּינָר', '5'),\n",
       " ('דְּלִי', '5'),\n",
       " ('לְמֵאָה', '5'),\n",
       " ('וְעֶשְׂרִים', '5'),\n",
       " ('מְגָרֵשׁ', '5'),\n",
       " ('נָדַר', '5'),\n",
       " ('לְבַטֵּל', '5'),\n",
       " ('יִשְׁתַּמֵּשׁ', '5'),\n",
       " ('סַכָּנָה', '5'),\n",
       " ('אֲכִילָה', '5'),\n",
       " ('לְשָׁנָה', '5'),\n",
       " ('בִּסְפִינָה', '5'),\n",
       " ('חַיֵּי', '4'),\n",
       " ('יָדְעָה', '4'),\n",
       " ('לְמֹשֶׁה', '4'),\n",
       " ('יִפְתַּח', '4'),\n",
       " ('הִתְחִיל', '4'),\n",
       " ('וְלֵוִי', '4'),\n",
       " ('וּבִרְכַּת', '4'),\n",
       " ('מִדַּת', '4'),\n",
       " ('לְעַם', '4'),\n",
       " ('קָרָא', '4'),\n",
       " ('טַבְלָא', '4'),\n",
       " ('שְׁתִי', '4'),\n",
       " ('דָּרַשׁ', '4'),\n",
       " ('גוּפָהּ', '4'),\n",
       " ('תִּקְרַב', '4'),\n",
       " ('מִינֵי', '4'),\n",
       " ('עֲנָבִים', '4'),\n",
       " ('חָטְאוּ', '4'),\n",
       " ('וָלָד', '4'),\n",
       " ('פּוֹתְחִין', '4'),\n",
       " ('וְהוֹצִיאוּהוּ', '4'),\n",
       " ('גְּבוֹהָה', '4'),\n",
       " ('שְׁמָא', '4'),\n",
       " ('לֵילֵךְ', '4'),\n",
       " ('חֲמֵשׁ', '4'),\n",
       " ('וּמְקַבֵּל', '4'),\n",
       " ('מַאֲהִיל', '4'),\n",
       " ('עָרֵב', '4'),\n",
       " ('בִּרְשׁוּתוֹ', '4'),\n",
       " ('לְאֶחָד', '4'),\n",
       " ('וְשֶׁבַע', '4'),\n",
       " ('לִיךְ', '4'),\n",
       " ('לֵילֵי', '4'),\n",
       " ('הֵא', '4'),\n",
       " ('בָּטְלוּ', '4'),\n",
       " ('לְנָכְרִי', '4'),\n",
       " ('חִזְקִיָּה', '4'),\n",
       " ('מֵאֶרֶץ', '4'),\n",
       " ('פְּלַג', '4'),\n",
       " ('קָבְעָה', '4'),\n",
       " ('חֲבוּרַת', '4'),\n",
       " ('פִרְחֵי', '4'),\n",
       " ('אֲחוֹרֵי', '4'),\n",
       " ('לֹוֶה', '4'),\n",
       " ('כַּלָּה', '4'),\n",
       " ('וְעַבְדֵי', '4'),\n",
       " ('מְתַקְּנָן', '4'),\n",
       " ('מִיּוֹסֵף', '4'),\n",
       " ('נַפְשָׁהּ', '4'),\n",
       " ('בָנִים', '4'),\n",
       " ('סִימָן', '4'),\n",
       " ('וְכָתַב', '4'),\n",
       " ('קָרְאוּ', '4'),\n",
       " ('דִּינָרִין', '4'),\n",
       " ('מִבְּנֵי', '4'),\n",
       " ('בִּשְׁאָר', '3'),\n",
       " ('פָּרָשָׁה', '3'),\n",
       " ('כָּרַע', '3'),\n",
       " ('וּמְבָרֵךְ', '3'),\n",
       " ('קָרְמוּ', '3'),\n",
       " ('סַלֵּי', '3'),\n",
       " ('תִּשְׁרֵי', '3'),\n",
       " ('הָאֲדָמָה', '3'),\n",
       " ('מַלְכוּת', '3'),\n",
       " ('קָמָה', '3'),\n",
       " ('הַמִּינִין', '3'),\n",
       " ('וּמִתְעַטֵּף', '3'),\n",
       " ('הַסָּמוּךְ', '3'),\n",
       " ('הִגִּיעָה', '3'),\n",
       " ('וְעָבַר', '3'),\n",
       " ('מַתְיָא', '3'),\n",
       " ('לְכֹהֲנִים', '3'),\n",
       " ('קָנוּ', '3'),\n",
       " ('דָּוִד', '3'),\n",
       " ('אָרִיג', '3'),\n",
       " ('בְּפֵרוּשׁ', '3'),\n",
       " ('לִפְלוֹנִי', '3'),\n",
       " ('וְחַיֵּי', '3'),\n",
       " ('וְיָדַע', '3'),\n",
       " ('יָמוּת', '3'),\n",
       " ('כַּרְשִׁינֵי', '3'),\n",
       " ('בִּימֵי', '3'),\n",
       " ('נוֹשְׂאִים', '3'),\n",
       " ('וְהוֹצִיאוּהָ', '3'),\n",
       " ('בְּבַת', '3'),\n",
       " ('וּלְמָחָר', '3'),\n",
       " ('הַמַּרְדַּעַת', '3'),\n",
       " ('לִשְׁאָר', '3'),\n",
       " ('קָדוֹשׁ', '3'),\n",
       " ('אַשּׁוּר', '3'),\n",
       " ('רְפוּאָה', '3'),\n",
       " ('טָבַח', '3'),\n",
       " ('מַאֲכַל', '3'),\n",
       " ('הַקְּבוּעָה', '3'),\n",
       " ('בְּפִי', '3'),\n",
       " ('חֲסָדִים', '3'),\n",
       " ('סָתַר', '3'),\n",
       " ('לְאַרְבַּע', '3'),\n",
       " ('לְרַבָּן', '3'),\n",
       " ('מַקִּיף', '3'),\n",
       " ('אַכְסַדְרָה', '3'),\n",
       " ('בְּחָמֵשׁ', '3'),\n",
       " ('בְּגוּפוֹ', '3'),\n",
       " ('לַשּׁוּק', '3'),\n",
       " ('גָמַר', '3'),\n",
       " ('מִבָּבֶל', '3'),\n",
       " ('עֲצֶרֶת', '3'),\n",
       " ('שָׁלְחוּ', '3'),\n",
       " ('גַּבָּן', '3'),\n",
       " ('בְּתַמּוּז', '3'),\n",
       " ('בְּסוּרְיָא', '3'),\n",
       " ('נָטַע', '3'),\n",
       " ('בַּחֲמִשִּׁים', '3'),\n",
       " ('חֲלִילָה', '3'),\n",
       " ('מְעַכֶּבֶת', '3'),\n",
       " ('הִפִּילָה', '3'),\n",
       " ('קְצִיר', '3'),\n",
       " ('דִינָרִין', '3'),\n",
       " ('הָיִינוּ', '2'),\n",
       " ('תְּמַהּ', '2'),\n",
       " ('אֲחִי', '2'),\n",
       " ('צַדִּיקִים', '2'),\n",
       " ('שָׁנוּ', '2'),\n",
       " ('בֵּיתִי', '2'),\n",
       " ('וְיוֹחָנָן', '2'),\n",
       " ('מֵאַבָּא', '2'),\n",
       " ('יוֹשְׁבוֹת', '2'),\n",
       " ('וְסִפְרֵי', '2'),\n",
       " ('פִּילָא', '2'),\n",
       " ('בָּנֶיךָ', '2'),\n",
       " ('יוֹנֵי', '2'),\n",
       " ('קְטָלָא', '2'),\n",
       " ('מִשְׁמָע', '2'),\n",
       " ('תְּלוּיִין', '2'),\n",
       " ('וְקִבְּלָהּ', '2'),\n",
       " ('חֲבִיבִין', '2'),\n",
       " ('מִשְׁקָל', '2'),\n",
       " ('וְרֵאשִׁית', '2'),\n",
       " ('וּלְבֵית', '2'),\n",
       " ('גְּזֵרָה', '2'),\n",
       " ('שֶׁתָּפוּג', '2'),\n",
       " ('יֵשֵׁב', '2'),\n",
       " ('צַוָּאר', '2'),\n",
       " ('גַּד', '2'),\n",
       " ('אֵיזוֹהִי', '2'),\n",
       " ('הָאֲרִי', '2'),\n",
       " ('מָתַי', '2'),\n",
       " ('גָּלִיל', '2'),\n",
       " ('וְלַיְלָה', '2'),\n",
       " ('וְאוֹמְרִין', '2'),\n",
       " ('וְהוֹצִיאוֹ', '2'),\n",
       " ('הוֹצִיאוּהוּ', '2'),\n",
       " ('מֹשֶׁה', '2'),\n",
       " ('וְתֵשַׁע', '2'),\n",
       " ('וּבְמַרְפְּקוֹ', '2'),\n",
       " ('בְּטַבְלָא', '2'),\n",
       " ('תְּשַׁמֵּשׁ', '2'),\n",
       " ('שָׁתוּ', '2'),\n",
       " ('מְשַׁלְשֵׁל', '2'),\n",
       " ('יִרְתוּן', '2'),\n",
       " ('מָלַח', '2'),\n",
       " ('בְּמִצְוָה', '2'),\n",
       " ('כְּשׁוּת', '2'),\n",
       " ('וּבִכְפִיפָה', '2'),\n",
       " ('יָצְתָה', '2'),\n",
       " ('שֶׁלֹא', '2'),\n",
       " ('טָב', '2'),\n",
       " ('תּוֹכֵחָה', '2'),\n",
       " ('בְּחֶבֶר', '2'),\n",
       " ('בִּבְשַׂר', '2'),\n",
       " ('הַדָּר', '2'),\n",
       " ('חָמוּר', '2'),\n",
       " ('בִּכְדֵי', '2'),\n",
       " ('וְנָגְעוּ', '2'),\n",
       " ('אֲבוֹתֵיכֶם', '2'),\n",
       " ('וּמִקְצָת', '2'),\n",
       " ('וְהֵיכָן', '2'),\n",
       " ('קְרֵבָה', '2'),\n",
       " ('תְּנַאי', '2'),\n",
       " ('לְתַחַת', '2'),\n",
       " ('גִּידִין', '2'),\n",
       " ('כְּרַבִּי', '2'),\n",
       " ('חָלָה', '2'),\n",
       " ('וּגְמִילוּת', '2'),\n",
       " ('גָדֵר', '2'),\n",
       " ('וּמֹשֶׁה', '2'),\n",
       " ('לִכְלָבִים', '2'),\n",
       " ('וְסוֹפֵר', '2'),\n",
       " ('דִּינַאי', '2'),\n",
       " ('וְעָלֶיךָ', '2'),\n",
       " ('סַמָּנִין', '2'),\n",
       " ('הַנְּסָרִים', '2'),\n",
       " ('חַם', '2'),\n",
       " ('אַרְזָא', '2'),\n",
       " ('כָּלֵה', '2'),\n",
       " ('אֲלֵיהֶם', '2'),\n",
       " ('וְכָלֵב', '2'),\n",
       " ('מַגָּל', '2'),\n",
       " ('סָתַם', '2'),\n",
       " ('גוּפֵי', '2'),\n",
       " ('הַחֲלוּקִין', '2'),\n",
       " ('מַחְכִּים', '2'),\n",
       " ('בְּסֵפֶר', '2'),\n",
       " ('וְשִׁמְעוֹן', '2'),\n",
       " ('הִוא', '2'),\n",
       " ('וּלְמָה', '2')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'רַבִּי'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_vecs = [tok_to_vec(word[0], dimension) for word in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_predictions = lang_clf.predict_proba(stop_vecs)\n",
    "\n",
    "print('\\t' + 'Hebrew      Aramaic')\n",
    "for i in range(len(stops)):\n",
    "    print(stops[i][0] + '\\t' + str(stop_predictions[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
